#!/bin/bash

# Deployment Script for Video Processing System
# Run this on the EC2 instance to deploy/update the application

set -e  # Exit on any error

echo "ğŸš€ Starting deployment of Video Processing System..."

# Check if Docker is installed
if ! command -v docker &> /dev/null; then
    echo "ğŸ“¦ Installing Docker..."
    sudo yum update -y
    sudo yum install -y docker
    sudo systemctl start docker
    sudo systemctl enable docker
    sudo usermod -aG docker $USER
    echo "âœ… Docker installed successfully"
else
    echo "âœ… Docker is already installed"
fi

# Check if Docker Compose is installed
if ! command -v docker-compose &> /dev/null; then
    echo "ğŸ“¦ Installing Docker Compose..."
    sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
    sudo chmod +x /usr/local/bin/docker-compose
    echo "âœ… Docker Compose installed successfully"
else
    echo "âœ… Docker Compose is already installed"
fi

# Create necessary directories
echo "ğŸ“ Creating necessary directories..."
mkdir -p uploads temp prometheus-data grafana-data

# Check if .env file exists
if [ ! -f .env ]; then
    echo "âš ï¸  Creating .env file..."
    cat > .env << EOF
# AWS Configuration
S3_BUCKET=video-processing-system-bucket
AWS_DEFAULT_REGION=ap-south-1
AWS_PROFILE=my-dev-profile  # Use the profile you created for your personal AWS account

# RabbitMQ Configuration
RABBITMQ_DEFAULT_USER=guest
RABBITMQ_DEFAULT_PASS=guest

# Add your AWS credentials here or use IAM roles (recommended)
# AWS_ACCESS_KEY_ID=your-access-key
# AWS_SECRET_ACCESS_KEY=your-secret-key
EOF
    echo "ğŸ“ Please edit .env file with your actual S3 bucket name!"
    echo "   You can find the bucket name from the provision script output."
else
    echo "âœ… .env file already exists"
fi

# Stop existing containers
echo "ğŸ›‘ Stopping existing containers..."
docker-compose down || true

# Remove old images to ensure we use the latest
echo "ğŸ—‘ï¸  Removing old images..."
docker image prune -f || true

# Build and start services
echo "ğŸ”¨ Building and starting services..."
docker-compose up --build -d

# Wait for services to be ready
echo "â³ Waiting for services to start..."
sleep 30

# Check service health
echo "ğŸ©º Checking service health..."
docker-compose ps

# Test API endpoint
echo "ğŸ§ª Testing API endpoint..."
sleep 10
if curl -f http://localhost:5001/health &> /dev/null; then
    echo "âœ… API service is healthy"
else
    echo "âš ï¸  API service may not be ready yet"
fi

# Display service URLs
echo ""
echo "ğŸ‰ Deployment completed!"
echo ""
echo "ğŸ“‹ Service URLs:"
echo "  ğŸŒ API Gateway:  http://$(curl -s http://checkip.amazonaws.com):5001"
echo "  ğŸ° RabbitMQ UI:  http://$(curl -s http://checkip.amazonaws.com):15672 (guest/guest)"
echo "  ğŸ“Š Prometheus:   http://$(curl -s http://checkip.amazonaws.com):9090"
echo "  ğŸ“ˆ Grafana:      http://$(curl -s http://checkip.amazonaws.com):3000 (admin/admin)"
echo ""
echo "ğŸ“ Next steps:"
echo "1. Upload a test video: curl -X POST -F \"file=@test.mp4\" http://your-ip:5001/upload"
echo "2. Monitor the processing in Grafana dashboard"
echo "3. Check RabbitMQ for message queue status"
echo ""
echo "ğŸ”§ To view logs:"
echo "  docker-compose logs -f [service-name]"
echo ""
echo "ğŸ”„ To restart services:"
echo "  docker-compose restart"
echo ""
